# Weka
Data mining by Weka

## Install
> https://www.cs.waikato.ac.nz/ml/weka/downloading.html
所需環境：Java VM ※Windows、Mac OS、Linux皆請下載includes Java VM版本（有分64bit或32bit）
* Windows版本64位元：weka-3-8-6-azul-zulu-windows.exe
* Mac OS X：weka-3-8-6-azul-zulu-osx.dmg
* Linux等其他平臺：weka-3-8-6-azul-zulu-linux.zip

## HW1
### 屬性常見可分析的有以下這幾點
* Instant：觀察值數量
* Name： 屬性名稱
* Type：屬性類型（nominal標記, numerical數字）
* Missing：該屬性不存在或未指定 兩種表示 實例數量或百分比
* Distinct：該屬性不同值的數量
* Unique：該屬性只有一個實例值的數量及百分比

### 關聯規則結果的幾項指標
* Confidence 信賴度：Ｌ發生的機率 分之 Ｌ與Ｒ同時發生的機率，即在發生L的情況下，R也會發生的條件機率。
* lift 提升度：Ｌ發生的機率✖️Ｒ發生的機率 分之 Ｌ與Ｒ同時發生的機率，當Lift=1的時候，代表L和R相互獨立，因此Lift的值越大(>1)，L和R之間的關係越密切。
* Leverage 槓桿度：Ｌ與Ｒ同時發生的機率 ➖ Ｌ發生的機率✖️Ｒ發生的機率，當Leverage=0的時候，代表L和R相互獨立，因此Leverage的值越大，L和R之間的關係越密切。
* Conviction 確信度：Ｌ與Ｒ同時發生的機率 分之 Ｌ發生的機率✖️Ｒ不發生的機率，用來衡量L和R之間的獨立性。從它和lift的關係來看，其對R取反，並代入Lift的公式之後求倒數，可以得知conviction的值越大，L和R之間的關係也越密切。

### HotSpot vs. 決策樹
#### HotSpot演算法
根據使用者所感興趣的目標項目來找尋最大化或最小化的一套樹狀結構規則，可於找尋類別類型與數值類型等各種資料類型的規則。
在處理類別變項的時候，HotSpot演算法會在最小支持度的限制下找尋該類別出現機率較多的變項；而處理連續變項的時候，HotSpot則會找出大於整體平均數的規則。
HotSpot演算法可以用於相當多場合，以醫療保險為例，研究者可以聚焦分析最高風險 (也就是死亡率最高) 的客戶群，最後可以找出他們共同出現的關聯規則分析結果為平均保險支出最多。

#### 決策樹
是資料探勘(data mining) 分類 (classifition)中的代表性演算法。
它是一種監督式演算法，一般是用於預測、建立模型上。可以協助我們將多維度的大量資料分析成為一些簡單易懂的規則。
舉例來說，我們要如何判斷一個職缺好不好呢？我們可以從合約期間、薪資、工時、休假等候選屬性來判斷。決策樹可以幫你分析出第一年薪資會是判斷工作好壞的重要屬性，其次是法定假日。

由上面可知：
熱點分析演算法則是目標屬性發生的情況下,各個屬性之條件機率。
決策樹的演算法可使我們很清楚的看出各項屬性對於目標屬性的影響大小程度,即哪一項屬性與目標屬性之間較具有較大的關聯性,更能看出在同屬某一屬性條件下,其他各屬性與目標屬性之間的關聯性,如此可以較有效的比較各個屬性對於目標屬性的影響關係為何。
所以其實兩種演算法皆能夠協助我們找到資料中目標值的關聯規則,然而其不同之處在於熱點分析是將各個屬性與目標屬性之間的規則分別呈現,故僅能知道其一種屬性與目標屬性的因果關係,而無法與其他屬性(可能影響的因素)交叉的比對;而決策樹是將各屬性合併起來交叉分析比對,其能夠顯現各個屬性影響關係的過程及與目標屬性的關聯結果等等。
那應用的部分就可以比較了～
「決策樹」可用於在短時間內需要比較各項不同屬性條件與因素而做出判斷的情況下,例如投資風險分析與投資抉擇等等;而「熱點分析」則能夠應用於單一事件發或社會現象發生時,尋找可能致其發生的關鍵因素,並也能夠藉此推估未來事件發生的走向等等。

## HW2
### LOF 
數值較大代表此觀察值的密度(各個變數的數值)低於其他觀察值中的密度(各個變數的數值),視為異常案例;而 LOF 數值較小代表此觀察值的密度(各個變數的數值)高於其他觀察值中的密度(各個變數的數值),視為普通案例。
### 由分群和異常偵測所找出的模式有何異同
分群的話是在相似的資料中，找一些特徵作為分群指標（如：有尖耳朵、黑白條紋、有蹄可能就被分群為斑馬），而群與群之間同質性低，但群內內部同質性高。
LOF適合在分群後使用，看看群與群間的距離，與群中跟變數和其他群變數的距離，如果某個變數與其他變數相較之下距離較遠，則會被判別為異常值。
實例中：
如果是想找尋特殊個案或容易成為布局策略中可能成為定時炸彈的人則用LOF(例如依照人格特質找出誰最可能是分屬於該群體成員特性的人；或者是看有沒有人是亂填問券的，找出異常的問券)，如果是想針對各個不同的群體擬出更精準的策略則適合用分群(如針對行銷對象背景的不同，依照不同需求的顧客推出適合他們方案)

## HW3
### 文字向量化流程 
![image](https://user-images.githubusercontent.com/69243911/197494471-abe227b7-5188-494a-9a0b-ba5ab925c463.png)
* 第一步驟：分解 也就是將文本拆成以n個字組成的詞彙 專業一點說法就是 以既有詞典為基礎，配合演算法來決定斷詞方式
* 第二步驟：轉換 因為有太多同義詞 但不同寫法 所以需要這個步驟來統一 不然會導致分類繁雜不統一
* 第三步驟：移除 將一些空格或是標點符號 甚至是我『的』作業 這個『的』移除 因為它無意義 不是一個有意義的詞彙
* 第四步驟：向量化 最後就是將前面的成果 轉為電腦可讀的資訊 畢竟我們是使用電腦來計算 所以一定要轉換為它看得懂的向量 （但我們不一定看得懂 甚至可以說一定不懂）

### 文字雲
由各種字詞組合成、如雲一般的圖形，稱作文字雲(Word Cloud)。
我們常在各種社交網站與新聞網站中看到這類圖形的蹤跡，文字雲的存在目的在於能讓閱讀者在不閱讀所有文章的前提下，快速聚焦在大批文章中的主要內容。
### Topic Modeling
基於LDA建立，LDA 有兩個基本的原則：
每篇文件都是由數個「主題 (Topic)」所組成
每個主題都可以使用數個重要的「用詞 (Word)」來描述，且相同的用詞可同時出現在不同的主題之間。
最核心要作的就是如何透過文件找到背後隱含的主題的結構。
簡單來說 事先定義好有限的（主題)，並透過觀察 (文件) 與 (用詞) 來計算出主題之間的關聯，以及各個文件的主題分佈


